"""
Service IA Recettes OPTIMISÃ‰
Utilise AIJsonParser + Cache

"""
import streamlit as st
import httpx
import logging
from typing import List, Dict, Optional
from pydantic import BaseModel, Field, validator

from src.core.models import TypeVersionRecetteEnum
from src.core.ai_json_parser import AIJsonParser, parse_list_response
from src.core.cache import Cache, RateLimit  # âœ… CORRIGÃ‰
from src.core.exceptions import AIServiceError, RateLimitError, handle_errors

logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SCHÃ‰MAS PYDANTIC (inchangÃ©s)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class IngredientAI(BaseModel):
    nom: str = Field(..., min_length=2, max_length=200)
    quantite: float = Field(..., gt=0, le=10000)
    unite: str = Field(..., min_length=1, max_length=50)
    optionnel: bool = False

    @validator("nom")
    def clean_nom(cls, v):
        return v.replace("'", "'").strip()

    @validator("quantite")
    def round_qty(cls, v):
        return round(v, 2)

class EtapeAI(BaseModel):
    ordre: int = Field(..., ge=1, le=50)
    description: str = Field(..., min_length=10, max_length=1000)
    duree: Optional[int] = Field(None, ge=0, le=300)

    @validator("description")
    def clean_desc(cls, v):
        return v.replace("'", "'").strip()

class RecetteAI(BaseModel):
    nom: str = Field(..., min_length=3, max_length=200)
    description: str = Field(..., min_length=10, max_length=2000)
    temps_preparation: int = Field(..., gt=0, le=300)
    temps_cuisson: int = Field(..., ge=0, le=300)
    portions: int = Field(..., gt=0, le=20)
    difficulte: str = Field("moyen", pattern="^(facile|moyen|difficile)$")
    type_repas: str = Field("dÃ®ner")
    saison: str = Field("toute_annÃ©e")
    categorie: Optional[str] = None

    est_rapide: bool = False
    est_equilibre: bool = True
    compatible_bebe: bool = False
    compatible_batch: bool = False
    congelable: bool = False

    ingredients: List[IngredientAI] = Field(..., min_items=1)
    etapes: List[EtapeAI] = Field(..., min_items=1)

    @validator("est_rapide", always=True)
    def auto_rapide(cls, v, values):
        prep = values.get("temps_preparation", 0)
        cuisson = values.get("temps_cuisson", 0)
        return (prep + cuisson) < 30

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SERVICE IA OPTIMISÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AIRecetteService:
    """
    Service de gÃ©nÃ©ration de recettes

    âœ… Utilise AIJsonParser (pas de parsing manuel)
    âœ… Utilise Cache multi-niveau
    âœ… Gestion d'erreurs avec decorators
    """

    def __init__(self, api_key: Optional[str] = None):
        try:
            self.api_key = api_key or st.secrets["mistral"]["api_key"]
            self.model = st.secrets.get("mistral", {}).get("model", "mistral-small-latest")
            self.base_url = "https://api.mistral.ai/v1"
            self.timeout = 60
            logger.info("âœ… AIRecetteService initialisÃ©")
        except KeyError:
            raise AIServiceError(
                "ClÃ© API Mistral manquante",
                user_message="Configuration IA manquante"
            )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # APPEL API AVEC CACHE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    @Cache.cached(ttl=1800, key="mistral_api_call")  # âœ… CORRIGÃ‰
    async def _call_mistral_cached(
            self,
            prompt: str,
            system_prompt: str = "",
            temperature: float = 0.7,
            max_tokens: int = 2000
    ) -> str:
        """
        Appel API avec cache intelligent multi-niveau

        âœ… Cache mÃ©moire (instantanÃ©)
        âœ… Cache session (persiste reruns)
        âœ… Cache fichier (persiste redÃ©marrages)
        """
        # VÃ©rifier rate limit
        can_call, error_msg = RateLimit.can_call()  # âœ… CORRIGÃ‰
        if not can_call:
            raise RateLimitError(error_msg, user_message=error_msg)

        logger.info(f"ğŸŒ Appel API Mistral (modÃ¨le: {self.model})")

        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                messages = []
                if system_prompt:
                    messages.append({"role": "system", "content": system_prompt})
                messages.append({"role": "user", "content": prompt})

                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": self.model,
                        "messages": messages,
                        "temperature": temperature,
                        "max_tokens": max_tokens,
                    },
                )

                response.raise_for_status()
                result = response.json()
                content = result["choices"][0]["message"]["content"]

                # Enregistrer l'appel
                RateLimit.record_call()  # âœ… CORRIGÃ‰

                logger.info(f"âœ… RÃ©ponse reÃ§ue ({len(content)} chars)")
                return content

        except httpx.HTTPError as e:
            logger.error(f"âŒ Erreur HTTP: {e}")
            raise AIServiceError(
                f"Erreur API Mistral: {str(e)}",
                user_message="L'IA est temporairement indisponible"
            )
        except Exception as e:
            logger.error(f"âŒ Erreur inattendue: {e}")
            raise AIServiceError(
                f"Erreur appel IA: {str(e)}",
                user_message="Erreur lors de l'appel IA"
            )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # GÃ‰NÃ‰RATION RECETTES
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    @handle_errors(show_in_ui=True)
    async def generate_recipes(
            self,
            count: int,
            filters: Dict,
            version_type: str = TypeVersionRecetteEnum.STANDARD.value
    ) -> List[Dict]:
        """
        GÃ©nÃ¨re des recettes avec parsing robuste

        âœ… Utilise AIJsonParser (pas de parsing manuel)
        âœ… Fallback automatique si Ã©chec
        âœ… Cache intelligent
        """
        try:
            # Construire prompts
            system_prompt = self._build_system_prompt(version_type)
            user_prompt = self._build_user_prompt(count, filters, version_type)

            logger.info(f"ğŸ¤– GÃ©nÃ©ration de {count} recette(s)")

            # Appeler l'IA (avec cache)
            response = await self._call_mistral_cached(
                prompt=user_prompt,
                system_prompt=system_prompt,
                temperature=0.7,
                max_tokens=2000
            )

            # âœ… Parser avec AIJsonParser (robuste)
            recettes = parse_list_response(
                response,
                RecetteAI,
                list_key="recettes",
                fallback_items=self._get_fallback_recipes(count)
            )

            # Convertir en dicts
            result = [r.dict() for r in recettes[:count]]

            # Ajouter images
            for recipe in result:
                recipe["url_image"] = self.generate_image_url(
                    recipe["nom"],
                    recipe["description"]
                )

            logger.info(f"âœ… {len(result)} recette(s) gÃ©nÃ©rÃ©e(s)")
            return result

        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration: {e}")
            raise AIServiceError(
                f"Ã‰chec gÃ©nÃ©ration: {str(e)}",
                user_message="Impossible de gÃ©nÃ©rer les recettes"
            )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PROMPTS (inchangÃ©s)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _build_system_prompt(self, version_type: str) -> str:
        """Prompt systÃ¨me ultra-strict"""
        base = (
            "Tu es un assistant JSON. Tu gÃ©nÃ¨res UNIQUEMENT du JSON valide.\n"
            "RÃˆGLES ABSOLUES:\n"
            "1. Commence DIRECTEMENT par {\n"
            "2. Termine DIRECTEMENT par }\n"
            "3. Utilise UNIQUEMENT des doubles guillemets\n"
            "4. Pas de markdown (```json)\n"
            "5. Pas de texte avant/aprÃ¨s le JSON\n\n"
            "Contexte: Chef cuisinier franÃ§ais expert."
        )

        if version_type == TypeVersionRecetteEnum.BEBE.value:
            base += "\n\nADAPTATION BÃ‰BÃ‰: 6-18 mois, sans sel/sucre ajoutÃ©, sans miel."
        elif version_type == TypeVersionRecetteEnum.BATCH_COOKING.value:
            base += "\n\nBATCH COOKING: Portions multiples, Ã©tapes parallÃ¨les."

        return base

    def _build_user_prompt(self, count: int, filters: Dict, version_type: str) -> str:
        """Prompt utilisateur avec critÃ¨res"""
        parts = [f"GÃ©nÃ¨re {count} recette(s) franÃ§aise(s)"]

        if filters.get("saison"):
            parts.append(f"de saison {filters['saison']}")
        if filters.get("is_quick"):
            parts.append("rapides (<30min)")
        if filters.get("is_balanced"):
            parts.append("Ã©quilibrÃ©es")
        if filters.get("type_repas"):
            parts.append(f"pour le {filters['type_repas']}")
        if filters.get("ingredients"):
            ings = ", ".join(filters["ingredients"][:5])
            parts.append(f"avec: {ings}")

        prompt = " ".join(parts) + ".\n\n"
        prompt += self._get_json_schema()
        prompt += "\n\nâš ï¸ UNIQUEMENT LE JSON, RIEN D'AUTRE !"

        return prompt

    def _get_json_schema(self) -> str:
        """SchÃ©ma JSON exemple"""
        return """{
  "recettes": [
    {
      "nom": "Gratin dauphinois",
      "description": "Gratin crÃ©meux aux pommes de terre",
      "temps_preparation": 20,
      "temps_cuisson": 60,
      "portions": 6,
      "difficulte": "moyen",
      "type_repas": "dÃ®ner",
      "saison": "toute_annÃ©e",
      "categorie": "FranÃ§ais",
      "est_rapide": false,
      "est_equilibre": true,
      "compatible_bebe": false,
      "compatible_batch": true,
      "congelable": true,
      "ingredients": [
        {"nom": "Pommes de terre", "quantite": 1.0, "unite": "kg", "optionnel": false},
        {"nom": "CrÃ¨me fraÃ®che", "quantite": 300, "unite": "mL", "optionnel": false}
      ],
      "etapes": [
        {"ordre": 1, "description": "Ã‰plucher et trancher les pommes de terre", "duree": 15},
        {"ordre": 2, "description": "Disposer en couches dans un plat", "duree": 5},
        {"ordre": 3, "description": "Verser la crÃ¨me et enfourner 60min Ã  180Â°C", "duree": 60}
      ]
    }
  ]
}"""

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # FALLBACK
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _get_fallback_recipes(self, count: int) -> List[Dict]:
        """Recettes de fallback si IA Ã©choue"""
        fallback = [
            {
                "nom": "PÃ¢tes au beurre",
                "description": "Recette simple et rapide pour dÃ©panner",
                "temps_preparation": 5,
                "temps_cuisson": 10,
                "portions": 4,
                "difficulte": "facile",
                "type_repas": "dÃ®ner",
                "saison": "toute_annÃ©e",
                "categorie": "Italien",
                "est_rapide": True,
                "est_equilibre": False,
                "compatible_bebe": False,
                "compatible_batch": False,
                "congelable": False,
                "ingredients": [
                    {"nom": "PÃ¢tes", "quantite": 400, "unite": "g", "optionnel": False},
                    {"nom": "Beurre", "quantite": 50, "unite": "g", "optionnel": False},
                ],
                "etapes": [
                    {"ordre": 1, "description": "Faire bouillir de l'eau salÃ©e", "duree": 5},
                    {"ordre": 2, "description": "Cuire les pÃ¢tes", "duree": 8},
                    {"ordre": 3, "description": "Ã‰goutter et mÃ©langer avec le beurre", "duree": 2},
                ],
            }
        ]

        return fallback[:count]

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # GÃ‰NÃ‰RATION IMAGE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def generate_image_url(self, recipe_name: str, description: str) -> str:
        """GÃ©nÃ¨re URL d'image (Unsplash)"""
        safe_name = recipe_name.replace(" ", ",").replace("'", "")
        return f"https://source.unsplash.com/400x300/?{safe_name},food,recipe,cooking"

# Instance globale
ai_recette_service = AIRecetteService()