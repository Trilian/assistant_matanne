"""
SQL Optimizer - Optimisation des requÃªtes SQLAlchemy.

FonctionnalitÃ©s :
- Ã‰coute des Ã©vÃ©nements SQLAlchemy
- Tracking automatique des requÃªtes
- DÃ©tection N+1 queries
- Suggestions d'optimisation
- Batch loading intelligent
"""

import logging
import re
import time
from collections import defaultdict
from contextlib import contextmanager
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Callable, TypeVar

import streamlit as st
from sqlalchemy import event
from sqlalchemy.engine import Engine
from sqlalchemy.orm import Query, Session, joinedload, selectinload

logger = logging.getLogger(__name__)

T = TypeVar("T")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TYPES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@dataclass
class QueryInfo:
    """Information sur une requÃªte SQL."""
    
    sql: str
    duration_ms: float
    timestamp: datetime = field(default_factory=datetime.now)
    table: str = ""
    operation: str = ""  # SELECT, INSERT, UPDATE, DELETE
    parameters: dict = field(default_factory=dict)


@dataclass
class N1Detection:
    """DÃ©tection de problÃ¨me N+1."""
    
    table: str
    parent_table: str
    count: int
    first_seen: datetime = field(default_factory=datetime.now)
    sample_query: str = ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LISTENER SQLALCHEMY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class SQLAlchemyListener:
    """
    Ã‰coute les Ã©vÃ©nements SQLAlchemy pour tracking.
    
    S'attache automatiquement Ã  l'engine pour capturer
    toutes les requÃªtes exÃ©cutÃ©es.
    """
    
    SESSION_KEY = "_sqlalchemy_query_log"
    _installed = False
    _current_query_start: dict = {}
    
    @classmethod
    def install(cls, engine: Engine) -> None:
        """
        Installe les listeners sur l'engine.
        
        Args:
            engine: SQLAlchemy Engine
        """
        if cls._installed:
            return
        
        @event.listens_for(engine, "before_cursor_execute")
        def before_execute(conn, cursor, statement, parameters, context, executemany):
            conn.info["query_start_time"] = time.perf_counter()
        
        @event.listens_for(engine, "after_cursor_execute")
        def after_execute(conn, cursor, statement, parameters, context, executemany):
            start_time = conn.info.pop("query_start_time", None)
            if start_time:
                duration_ms = (time.perf_counter() - start_time) * 1000
                cls._log_query(statement, duration_ms, parameters)
        
        cls._installed = True
        logger.info("âœ… SQLAlchemy listener installÃ©")
    
    @classmethod
    def _log_query(cls, sql: str, duration_ms: float, parameters: Any) -> None:
        """Enregistre une requÃªte dans le log."""
        # Extraire table et opÃ©ration
        operation = cls._extract_operation(sql)
        table = cls._extract_table(sql)
        
        query_info = QueryInfo(
            sql=sql[:500],  # Tronquer
            duration_ms=duration_ms,
            table=table,
            operation=operation,
            parameters=dict(parameters) if isinstance(parameters, dict) else {},
        )
        
        # Sauvegarder dans session
        if cls.SESSION_KEY not in st.session_state:
            st.session_state[cls.SESSION_KEY] = []
        
        st.session_state[cls.SESSION_KEY].append(query_info)
        
        # Garder seulement les 200 derniÃ¨res
        if len(st.session_state[cls.SESSION_KEY]) > 200:
            st.session_state[cls.SESSION_KEY] = st.session_state[cls.SESSION_KEY][-200:]
        
        # Log si lente
        if duration_ms > 100:
            logger.warning(f"âš ï¸ RequÃªte lente ({duration_ms:.0f}ms) sur {table}: {operation}")
    
    @classmethod
    def _extract_operation(cls, sql: str) -> str:
        """Extrait le type d'opÃ©ration SQL."""
        sql_upper = sql.strip().upper()
        for op in ["SELECT", "INSERT", "UPDATE", "DELETE", "CREATE", "ALTER", "DROP"]:
            if sql_upper.startswith(op):
                return op
        return "OTHER"
    
    @classmethod
    def _extract_table(cls, sql: str) -> str:
        """Extrait le nom de la table principale."""
        patterns = [
            r"FROM\s+[\"']?(\w+)[\"']?",
            r"INTO\s+[\"']?(\w+)[\"']?",
            r"UPDATE\s+[\"']?(\w+)[\"']?",
            r"TABLE\s+[\"']?(\w+)[\"']?",
        ]
        
        for pattern in patterns:
            match = re.search(pattern, sql, re.IGNORECASE)
            if match:
                return match.group(1)
        
        return "unknown"
    
    @classmethod
    def get_queries(cls) -> list[QueryInfo]:
        """Retourne toutes les requÃªtes loggÃ©es."""
        return st.session_state.get(cls.SESSION_KEY, [])
    
    @classmethod
    def get_stats(cls) -> dict:
        """Calcule les statistiques des requÃªtes."""
        queries = cls.get_queries()
        
        if not queries:
            return {
                "total": 0,
                "by_operation": {},
                "by_table": {},
                "slow_queries": [],
                "avg_time_ms": 0,
            }
        
        by_operation = defaultdict(int)
        by_table = defaultdict(int)
        total_time = 0
        slow = []
        
        for q in queries:
            by_operation[q.operation] += 1
            by_table[q.table] += 1
            total_time += q.duration_ms
            
            if q.duration_ms > 100:
                slow.append(q)
        
        return {
            "total": len(queries),
            "by_operation": dict(by_operation),
            "by_table": dict(sorted(by_table.items(), key=lambda x: x[1], reverse=True)[:10]),
            "slow_queries": slow[-10:],
            "avg_time_ms": round(total_time / len(queries), 2),
        }
    
    @classmethod
    def clear(cls) -> None:
        """Vide le log."""
        st.session_state[cls.SESSION_KEY] = []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DÃ‰TECTEUR N+1
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class N1Detector:
    """
    DÃ©tecte les problÃ¨mes N+1 queries.
    
    Un problÃ¨me N+1 se produit quand on fait N requÃªtes
    supplÃ©mentaires pour charger des relations, au lieu
    d'une seule requÃªte avec JOIN.
    """
    
    SESSION_KEY = "_n1_detections"
    THRESHOLD = 5  # Min requÃªtes similaires pour alerter
    
    @classmethod
    def analyze(cls) -> list[N1Detection]:
        """
        Analyse les requÃªtes rÃ©centes pour dÃ©tecter N+1.
        
        Returns:
            Liste des dÃ©tections N+1
        """
        queries = SQLAlchemyListener.get_queries()
        
        if len(queries) < cls.THRESHOLD:
            return []
        
        # Grouper par pattern de requÃªte
        patterns = defaultdict(list)
        
        for q in queries:
            if q.operation == "SELECT":
                # Normaliser la requÃªte (retirer les valeurs)
                pattern = cls._normalize_query(q.sql)
                patterns[pattern].append(q)
        
        # DÃ©tecter les patterns rÃ©pÃ©tÃ©s
        detections = []
        
        for pattern, pattern_queries in patterns.items():
            if len(pattern_queries) >= cls.THRESHOLD:
                # Probable N+1
                table = pattern_queries[0].table
                
                detection = N1Detection(
                    table=table,
                    parent_table=cls._guess_parent_table(pattern_queries),
                    count=len(pattern_queries),
                    sample_query=pattern_queries[0].sql[:200],
                )
                detections.append(detection)
        
        # Sauvegarder
        st.session_state[cls.SESSION_KEY] = detections
        
        if detections:
            logger.warning(f"âš ï¸ {len(detections)} problÃ¨me(s) N+1 dÃ©tectÃ©(s)")
        
        return detections
    
    @classmethod
    def _normalize_query(cls, sql: str) -> str:
        """Normalise une requÃªte pour comparaison."""
        # Retirer les valeurs numÃ©riques
        normalized = re.sub(r'\b\d+\b', '?', sql)
        # Retirer les strings
        normalized = re.sub(r"'[^']*'", "'?'", normalized)
        return normalized
    
    @classmethod
    def _guess_parent_table(cls, queries: list[QueryInfo]) -> str:
        """Devine la table parente d'un N+1."""
        # Chercher des patterns de FK
        for q in queries:
            match = re.search(r'WHERE\s+["\']?(\w+_id)["\']?\s*=', q.sql, re.IGNORECASE)
            if match:
                fk = match.group(1)
                return fk.replace("_id", "")
        return "unknown"
    
    @classmethod
    def get_detections(cls) -> list[N1Detection]:
        """Retourne les dÃ©tections N+1."""
        return st.session_state.get(cls.SESSION_KEY, [])
    
    @classmethod
    def get_suggestions(cls) -> list[str]:
        """
        GÃ©nÃ¨re des suggestions pour corriger les N+1.
        
        Returns:
            Liste de suggestions
        """
        detections = cls.get_detections()
        suggestions = []
        
        for d in detections:
            if d.parent_table != "unknown":
                suggestions.append(
                    f"ğŸ’¡ Table '{d.table}': Utiliser `joinedload({d.parent_table})` "
                    f"ou `selectinload({d.parent_table})` pour Ã©viter {d.count} requÃªtes"
                )
            else:
                suggestions.append(
                    f"ğŸ’¡ Table '{d.table}': {d.count} requÃªtes similaires dÃ©tectÃ©es. "
                    f"ConsidÃ©rer un eager loading des relations."
                )
        
        return suggestions


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BATCH LOADER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class BatchLoader:
    """
    Utilitaires pour le chargement par lots.
    """
    
    @staticmethod
    def load_in_batches(
        query: Query,
        batch_size: int = 100,
        callback: Callable[[list], None] | None = None,
    ) -> list:
        """
        Charge les rÃ©sultats d'une requÃªte par lots.
        
        Args:
            query: RequÃªte SQLAlchemy
            batch_size: Taille des lots
            callback: Fonction appelÃ©e pour chaque lot
            
        Returns:
            Tous les rÃ©sultats
        """
        results = []
        offset = 0
        
        while True:
            batch = query.offset(offset).limit(batch_size).all()
            
            if not batch:
                break
            
            results.extend(batch)
            
            if callback:
                callback(batch)
            
            offset += batch_size
            
            # Ã‰viter boucle infinie
            if len(batch) < batch_size:
                break
        
        return results
    
    @staticmethod
    def chunked(items: list, chunk_size: int = 100):
        """
        GÃ©nÃ©rateur qui dÃ©coupe une liste en chunks.
        
        Args:
            items: Liste Ã  dÃ©couper
            chunk_size: Taille des chunks
            
        Yields:
            Chunks de la liste
        """
        for i in range(0, len(items), chunk_size):
            yield items[i:i + chunk_size]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# QUERY BUILDER OPTIMISÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class OptimizedQueryBuilder:
    """
    Builder de requÃªtes avec optimisations automatiques.
    """
    
    def __init__(self, session: Session, model: type):
        """
        Initialise le builder.
        
        Args:
            session: Session SQLAlchemy
            model: ModÃ¨le de base
        """
        self._session = session
        self._model = model
        self._query = session.query(model)
        self._eager_loads = []
        self._filters = []
        self._order_by = None
        self._limit = None
        self._offset = None
    
    def eager_load(self, *relationships: str) -> "OptimizedQueryBuilder":
        """
        Ajoute des relations en eager loading.
        
        Args:
            relationships: Noms des relations
            
        Returns:
            Self pour chaÃ®nage
        """
        for rel in relationships:
            self._eager_loads.append(rel)
        return self
    
    def filter_by(self, **kwargs) -> "OptimizedQueryBuilder":
        """
        Ajoute des filtres.
        
        Args:
            kwargs: Filtres clÃ©=valeur
            
        Returns:
            Self pour chaÃ®nage
        """
        self._filters.append(kwargs)
        return self
    
    def order(self, column: str, desc: bool = False) -> "OptimizedQueryBuilder":
        """
        DÃ©finit l'ordre.
        
        Args:
            column: Colonne de tri
            desc: Ordre descendant
            
        Returns:
            Self pour chaÃ®nage
        """
        self._order_by = (column, desc)
        return self
    
    def paginate(self, page: int = 1, per_page: int = 20) -> "OptimizedQueryBuilder":
        """
        Applique pagination.
        
        Args:
            page: NumÃ©ro de page (1-based)
            per_page: Ã‰lÃ©ments par page
            
        Returns:
            Self pour chaÃ®nage
        """
        self._offset = (page - 1) * per_page
        self._limit = per_page
        return self
    
    def build(self) -> Query:
        """
        Construit la requÃªte optimisÃ©e.
        
        Returns:
            Query SQLAlchemy
        """
        query = self._query
        
        # Appliquer eager loading
        for rel in self._eager_loads:
            if hasattr(self._model, rel):
                # Utiliser selectinload pour les collections
                query = query.options(selectinload(getattr(self._model, rel)))
        
        # Appliquer filtres
        for filter_kwargs in self._filters:
            query = query.filter_by(**filter_kwargs)
        
        # Appliquer ordre
        if self._order_by:
            column, desc = self._order_by
            col_attr = getattr(self._model, column, None)
            if col_attr is not None:
                query = query.order_by(col_attr.desc() if desc else col_attr)
        
        # Appliquer pagination
        if self._offset is not None:
            query = query.offset(self._offset)
        if self._limit is not None:
            query = query.limit(self._limit)
        
        return query
    
    def all(self) -> list:
        """ExÃ©cute et retourne tous les rÃ©sultats."""
        return self.build().all()
    
    def first(self) -> Any | None:
        """ExÃ©cute et retourne le premier rÃ©sultat."""
        return self.build().first()
    
    def count(self) -> int:
        """Compte les rÃ©sultats."""
        return self.build().count()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPOSANTS UI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def render_sql_analysis():
    """Affiche l'analyse SQL dans l'interface."""
    
    stats = SQLAlchemyListener.get_stats()
    
    with st.expander("ğŸ—ƒï¸ Analyse SQL", expanded=False):
        
        if stats["total"] == 0:
            st.info("Aucune requÃªte enregistrÃ©e")
            return
        
        # MÃ©triques gÃ©nÃ©rales
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total requÃªtes", stats["total"])
        with col2:
            st.metric("Temps moyen", f"{stats['avg_time_ms']}ms")
        with col3:
            slow_count = len(stats["slow_queries"])
            st.metric(
                "RequÃªtes lentes",
                slow_count,
                delta=f"-{slow_count}" if slow_count > 0 else None,
                delta_color="inverse",
            )
        
        # Par opÃ©ration
        st.caption("ğŸ“Š Par opÃ©ration:")
        for op, count in stats["by_operation"].items():
            st.progress(count / stats["total"], text=f"{op}: {count}")
        
        # DÃ©tection N+1
        detections = N1Detector.analyze()
        if detections:
            st.warning(f"âš ï¸ {len(detections)} problÃ¨me(s) N+1 dÃ©tectÃ©(s)")
            
            for suggestion in N1Detector.get_suggestions():
                st.caption(suggestion)
        
        # Boutons
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ Analyser N+1", key="analyze_n1"):
                N1Detector.analyze()
                st.rerun()
        with col2:
            if st.button("ğŸ—‘ï¸ Vider log", key="clear_sql_log"):
                SQLAlchemyListener.clear()
                st.rerun()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXPORTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


__all__ = [
    # Classes
    "QueryInfo",
    "N1Detection",
    "SQLAlchemyListener",
    "N1Detector",
    "BatchLoader",
    "OptimizedQueryBuilder",
    # UI
    "render_sql_analysis",
]
