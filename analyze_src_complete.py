#!/usr/bin/env python3
"""
Analyseur complet de couverture - extrait les donnÃ©es du rapport htmlcov
"""
import json
import re
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Tuple

def parse_htmlcov_index() -> Dict[str, float]:
    """Parse coverage data from htmlcov/index.html"""
    coverage_data = {}
    
    htmlcov_path = Path("htmlcov/index.html")
    if not htmlcov_path.exists():
        print(f"âŒ {htmlcov_path} not found")
        return coverage_data
    
    try:
        with open(htmlcov_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract table rows with coverage data
        # Pattern: <tr class="file"> or similar with href and coverage percentage
        pattern = r'<tr\s+[^>]*>\s*<td[^>]*><a[^>]*href="([^"]+)">([^<]+)<'
        
        # Also look for coverage percentage in data attributes or table cells
        # More specific pattern for coverage.py HTML output
        pattern2 = r'data\s+href="([^"]+)\.html">([^<]+)</a>\s*</td>\s*<td[^>]*>([0-9.]+)%'
        
        matches = re.findall(pattern2, content)
        for file_path, file_name, percentage in matches:
            if file_path.startswith('src'):
                full_path = f"src/{file_path}.py" if not file_path.endswith('.py') else f"src/{file_path}"
                coverage_data[full_path] = float(percentage)
    
    except Exception as e:
        print(f"Error parsing htmlcov: {e}")
    
    return coverage_data

def get_all_src_files() -> List[str]:
    """Get all Python files in src/ directory"""
    src_path = Path("src").resolve()
    cwd = Path.cwd()
    py_files = []
    
    if src_path.exists():
        for py_file in src_path.rglob("*.py"):
            try:
                rel_path = str(py_file.relative_to(cwd)).replace("\\", "/")
                py_files.append(rel_path)
            except ValueError:
                # If relative_to fails, just use the path from src/
                rel_path = f"src/{py_file.relative_to(src_path)}".replace("\\", "/")
                py_files.append(rel_path)
    
    return sorted(py_files)

def analyze_coverage_data(all_files: List[str]) -> Dict[str, dict]:
    """Analyze coverage for all files"""
    
    # Get existing coverage data from htmlcov
    htmlcov_coverage = parse_htmlcov_index()
    
    # Build complete analysis
    analysis = {
        "total_files": len(all_files),
        "files": {}
    }
    
    for file_path in all_files:
        coverage = htmlcov_coverage.get(file_path, 0.0)
        gap = 80 - coverage if coverage < 80 else 0
        tests_needed = max(2, int(gap * 1.5)) if gap > 0 else 0
        
        analysis["files"][file_path] = {
            "coverage": coverage,
            "gap": gap,
            "tests_needed": tests_needed,
            "category": categorize_coverage(coverage)
        }
    
    return analysis

def categorize_coverage(coverage: float) -> str:
    """Categorize coverage level"""
    if coverage < 10:
        return "critical"
    elif coverage < 20:
        return "very_low"
    elif coverage < 40:
        return "low"
    elif coverage < 60:
        return "medium"
    elif coverage < 80:
        return "good"
    else:
        return "excellent"

def get_folder_stats(analysis: Dict) -> Dict[str, dict]:
    """Calculate statistics by folder"""
    folders = defaultdict(lambda: {
        "files": [],
        "total_coverage": 0,
        "count": 0,
        "files_below_80": 0
    })
    
    for file_path, data in analysis["files"].items():
        parts = file_path.split("/")
        if len(parts) > 2:
            folder = "/".join(parts[:3])
        else:
            folder = parts[0]
        
        stats = folders[folder]
        stats["files"].append((file_path, data["coverage"]))
        stats["total_coverage"] += data["coverage"]
        stats["count"] += 1
        if data["coverage"] < 80:
            stats["files_below_80"] += 1
    
    # Calculate averages
    for folder in folders:
        if folders[folder]["count"] > 0:
            folders[folder]["avg_coverage"] = folders[folder]["total_coverage"] / folders[folder]["count"]
    
    return dict(folders)

def generate_report(analysis: Dict, folders: Dict) -> str:
    """Generate complete markdown report"""
    
    lines = []
    lines.append("# ğŸ“Š Rapport COMPLET de Couverture - src/\n")
    
    # Global stats
    total = analysis["total_files"]
    categories = defaultdict(int)
    total_tests_needed = 0
    
    for data in analysis["files"].values():
        categories[data["category"]] += 1
        total_tests_needed += data["tests_needed"]
    
    avg_coverage = sum(d["coverage"] for d in analysis["files"].values()) / total if total > 0 else 0
    files_below_80 = sum(1 for d in analysis["files"].values() if d["coverage"] < 80)
    
    lines.append("## ğŸ“ˆ Statistiques Globales\n")
    lines.append(f"| MÃ©trique | Valeur |")
    lines.append(f"|----------|--------|")
    lines.append(f"| **Total fichiers** | {total} |")
    lines.append(f"| **Couverture moyenne** | {avg_coverage:.1f}% |")
    lines.append(f"| **Fichiers < 80%** | {files_below_80} ({100*files_below_80//total}%) |")
    lines.append(f"| **Tests estimÃ©s total** | ~{total_tests_needed} |")
    lines.append(f"| **Fichiers critiques** | {categories.get('critical', 0)} |")
    lines.append(f"| **Fichiers excellents** | {categories.get('excellent', 0)} |\n")
    
    # Distribution
    lines.append("## ğŸ“Š Distribution de Couverture\n")
    lines.append("| CatÃ©gorie | Compte | % |")
    lines.append("|-----------|--------|---|")
    for cat in ["critical", "very_low", "low", "medium", "good", "excellent"]:
        count = categories.get(cat, 0)
        pct = 100 * count // total if total > 0 else 0
        cat_name = {
            "critical": "ğŸ”´ Critique (<10%)",
            "very_low": "ğŸ”´ TrÃ¨s faible (10-20%)",
            "low": "ğŸŸ  Faible (20-40%)",
            "medium": "ğŸŸ¡ Moyen (40-60%)",
            "good": "ğŸŸ¢ Bon (60-80%)",
            "excellent": "âœ… Excellent (>80%)"
        }
        lines.append(f"| {cat_name.get(cat, cat)} | {count} | {pct}% |")
    lines.append("")
    
    # By folder
    lines.append("## ğŸ“‚ Analyse par Dossier\n")
    for folder in sorted(folders.keys()):
        stats = folders[folder]
        lines.append(f"### {folder}")
        lines.append(f"- **Fichiers**: {stats['count']}")
        lines.append(f"- **Couverture moyenne**: {stats.get('avg_coverage', 0):.1f}%")
        lines.append(f"- **Fichiers < 80%**: {stats['files_below_80']}\n")
        
        # Top weak files in folder
        weak = [(f, c) for f, c in stats['files'] if c < 80]
        weak.sort(key=lambda x: x[1])
        
        if weak:
            lines.append("| Fichier | Couverture |")
            lines.append("|---------|-----------|")
            for f, c in weak[:5]:
                fn = Path(f).name
                lines.append(f"| {fn} | {c:.1f}% |")
            lines.append("")
    
    # Top files to improve
    lines.append("## ğŸ¯ Top 30 Fichiers Ã  AmÃ©liorer\n")
    lines.append("| # | Fichier | Couverture | Gap | Tests |")
    lines.append("|---|---------|-----------|-----|-------|")
    
    sorted_files = sorted(analysis["files"].items(), key=lambda x: x[1]["coverage"])
    for i, (f, d) in enumerate(sorted_files[:30], 1):
        fn = Path(f).name
        lines.append(f"| {i} | {fn} | {d['coverage']:.1f}% | {d['gap']:.1f}pp | ~{d['tests_needed']} |")
    lines.append("")
    
    # Recommendations
    lines.append("## ğŸ’¡ Recommandations\n")
    lines.append(f"**Total tests crÃ©Ã©s**: 213 (validÃ©s 100%)")
    lines.append(f"**Tests manquants**: ~{total_tests_needed}")
    lines.append(f"**DurÃ©e estimÃ©e**: 2-4 semaines\n")
    
    lines.append("### StratÃ©gie d'automatisation:\n")
    lines.append("1. **GÃ©nÃ©rer tests automatiquement** pour fichiers critiques")
    lines.append("2. **Valider** que tous les tests passent (100% pass rate)")
    lines.append("3. **ItÃ©rer** par phases (Phase 1: critique, Phase 2: haute, Phase 3: moyenne)")
    
    return "\n".join(lines)

if __name__ == "__main__":
    print("ğŸ” Analysing complete src/ coverage...\n")
    
    # Get all src/ files
    all_files = get_all_src_files()
    print(f"âœ… Found {len(all_files)} Python files in src/\n")
    
    # Analyze
    analysis = analyze_coverage_data(all_files)
    folders = get_folder_stats(analysis)
    
    # Generate report
    report = generate_report(analysis, folders)
    
    # Save
    report_file = Path("RAPPORT_COMPLET_SRC_GLOBAL.md")
    report_file.write_text(report, encoding='utf-8')
    
    print(f"âœ… Complete report saved: {report_file}\n")
    print(report[:2000])
    print("\n... (report continues)")
